<?xml version="1.0" encoding="UTF-8"?>
<partidas>
    <partida>
        <etiqueta />
        <folio>13</folio>
        <cara>v</cara>
        <id>25</id>
        <nombre> Mariano M Hernan y gomez</nombre>
        <texto>a los <fecha>seis días del mes de diciembre del año dos mil ventitres</fecha>:
La Unión Europea (UE) busca poner fin a más de dos años y medio de complicadas y opacas negociaciones para aprobar definitivamente la nueva ley de inteligencia artificial (IA). Este miércoles, las instituciones comunitarias se reunirán con la intención de alumbrar un texto definitivo que ponga límites al uso de esta tecnología. Sin embargo, la pública falta de acuerdo entre las partes amenaza con debilitar un proyecto legislativo que se inclina en favor de los gigantes del sector.

Las universidades a distancia del futuro usarán el reconocimiento facial para combatir la suplantación
MEDIDA PIONERA Y POLÉMICA
La ley de la inteligencia artificial, en la recta final: estos son los riesgos que la UE quiere regular
Uno de los grandes puntos conflictivos de la ley es cómo controlar los llamados modelos fundacionales, el corazón de herramientas de IA generativa como ChatGPT. Aunque hace un par de meses parecía haber consenso sobre la necesidad de fijar normas estrictas, en las últimas semanas Francia, Alemania e Italia se han opuesto a esos requerimientos alegando que perjudicarán la innovación y han presionado para una autoregulación que quede en manos de grandes empresas como OpenAI, Microsoft o Google. "La normativa sobre IA aún no está madura", advirtió este martes Volker Wissing, ministro alemán de Transporte e Infraestructura Digital.


El bloqueo de estos tres países, particularmente influyentes, indigna al Parlamento Europeo, que en junio aprobó un marco más duro que obliga a las compañías a identificar el contenido generado por IA, a explicar si han entrenado sus aplicaciones con materiales protegidos por los derechos de autor y a estar sujetas a reclamaciones de los usuarios. Organizaciones en defensa de los derechos digitales y notables expertos en IA han apoyado esa posición. "Reducir partes fundamentales de la ley a un ejercicio de autorregulación tendría consecuencias devastadoras para el mundo", ha advertido el neurocientífico cognitivo Gary Marcus.


Presión para España
An AI (Artificial Intelligence) sign is seen at the World Artificial Intelligence Conference (WAIC) in Shanghai
TENSAS NEGOCIACIONES
La falta de acuerdo en la Unión Europea pone en peligro la regulación de la inteligencia artificial
El desacuerdo entre ambos bloques complica la mediación de España, que este sementre preside el Consejo de la UE y por eso coordina las negociaciones. El Gobierno de Pedro Sánchez se ha marcado como prioridad aprobar esa pionera medida legislativa antes de que la presidencia española concluya a finales de mes y pase a manos de Bélgica. El tiempo juega en su contra. Quizás por eso, la última propuesta española plantea "unas obligaciones muy limitadas" para las empresas, según ha adelantado EL PAÍS.

La Comisión Europea propuso la regulación de la IA por primera vez el 21 de abril de 2021. A finales del año pasado la ley parecía lista, pero la irrupción de ChatGPT obligó a los legisladores a introducir cambios. La posición aprobada en junio por la Eurocámara establece una normativa más o menos estricta según los riesgos que comporte esta tecnología. Así, habrá tres categorías. Los sistemas que supongan un "riesgo inaceptable", como el reconocimiento facial, serán prohibidos. Los de "riesgo alto" deberán ser evaluados y cumplir con ciertas obligaciones. Por último, los de "riesgo limitado" solo tendrán que aplicar criterios de transparencia.

Vigilancia policial
Un grupo de migrantes marroquíes en las inmediaciones de la valla de Ceuta, a 17 de mayo de 2021.
VIGILANCIA EN LA FRONTERA
Más de 100 oenegés denuncian "vacíos" en la regulación de la inteligencia artificial que podrían exponer a los migrantes
Esta clasificación por riesgos entraña problemas no menores. Más de un centenar de onegés europeas han denunciado que la ley incluye un "vacío legal" que permitirá a los desarrolladores decidir si sus productos tecnológicos son o no peligrosos, dándoles así una vía para incumplir con los criterios más estrictos. "Si esto se aprueba la ley será inútil", explicó Caterina Rodelli, analista de Access Now, a EL PERIÓDICO.

Noticias relacionadas
Recorre Barcelona subido en un taxi: el último videojuego
Apocalípticos e integrados de la Inteligencia Artificial
La sociedad civil también alerta que la propuesta que ahora está sobre la mesa incluye excepciones para que tecnologías de "riesgo inaceptable" como la vigilancia biométrica sí puedan ser usadas por la policía en algunas situaciones y para controlar la inmigración en las fronteras de la UE. "La IA en las fuerzas del orden se dirige de forma desproporcionada a comunidades ya marginadas, socava los derechos legales y procesales y permite la vigilancia masiva", advierte un comunicado publicado hace una semana.

La falta de tiempo apremia a España. "Estamos teniendo que lidiar con muchos grupos de presión", confesó ayer el comisario europeo de Mercado Interior y Servicios, Thierry Breton, remarcando que no alcanzar un acuerdo no es una opción. La secretaria de Digitalización e Inteligencia Artificial española, Carme Artigas, se mostró optimista, pero las oenegés temen que las prisas terminen cristalizando en una ley descafeinada y llena de vacíos.</texto>
<firma>Eduardo etc etc</firma>



        <firma>Eduardo etc etc</firma>
    </partida>
</partidas>